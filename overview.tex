\section{Overview of our Approach}\label{sec:overview}
\begin{figure*}[t]
   \includegraphics[scale=0.75]{Framework}
  \hspace*{50mm} \includegraphics[scale=0.75]{Fig-backbone}
   \caption{Overview of our approach}
   \label{flow}
\end{figure*}

Figure \ref{flow} presents the overview of our approach \tool, which consists of three components. Taking a satisfiable formula
$\Phi$ as an input, \tool first computes an under-approximation $\NBLap(\Phi)\subseteq \NBL(\Phi)$ of the non-backbone of
$\Phi$. Then, \tool computes an approximation $\BLap(\Phi)$ of the backbone of $\Phi$ based on the set $\NBLap(\Phi)$, where each literal $l\in \BLap(\Phi)$ has a high possibility to be a backbone literal of $\Phi$.
Finally, \tool removes non-backbone literals from $\BLap(\Phi)$ and adds backbone literals into $\BLap(\Phi)$ to compute the exact backbone of $\Phi$.

As shown in Figure \ref{flow}, $\NBLap(\Phi)$ is only contains non-backbone literals, there are still other non-backbone literals that are not in $\NBLap(\Phi)$.
$\BLap(\Phi)$ contains both backbone literals and non-backbone literals, but most of the literals in $\BLap(\Phi)$ are backbone literals. There may exists overlapping between $\NBLap(\Phi)$ and $\BLap(\Phi)$.
In iterative testing (step 3), experiments show that solving time are saved by test the literals in $\BLap(\Phi)$ first, since it's more likely to test more backbone literals first. With more known backbone literals, SAT testings are accelerated.

\medskip
\noindent{\bf Computing an under-approximation of non-backbone.}
Given a satisfiable formula $\Phi$, we first compute a model $\lambda$ of $\Phi$ by calling a SAT solver.
From the model $\lambda$, we compute a base under-approximation of non-backbone.
Later, we apply a Greedy-based algorithm to add more non-backbone literals into the base under-approximation, which results in the
under-approximation $\NBLap(\Phi)$.

The algorithm iteratively changes the original model $\lambda$, exactly one literal has changed its assignment at each iteration. Therefore, suppose there are k iterations in Greedy-based Algorithm, there are k literals have different assignments compared to the original model $\lambda$. With more diversiform models, more non-backbone literals are found. There is a heuristic strategy for Greedy-based algorithm, minimal appearance clauses number of a given variable and variables in clauses that have more satisfied literals. If a variable appears in a clause, this clause is a appearance clauses of the given variable, changing the assignment of a variable with minimal appearances number influences the least number of clauses, which in turn has a higher possibility to find another model.

\medskip
\noindent{\bf Computing an approximation of backbone.}
At this step, we apply a Whitening-based algorithm to compute the approximation $\BLap(\Phi)$.
Whitening Algorithm was used to compute \emph{whiten node}, that are the nodes can be colored as white without changing the color of its adjacent nodes in a graph coloring problem.
Whitening Algorithm aimed at finding essential nodes in a coloring graph problem, it returns nodes that are not colored as white. If a node is considered as essential, it will be returned by Whitening Algorithm.

We consider essential nodes as backbone literals in backbone computing. When applied to non-backbone computing, Whitening Algorithm may return parts of non-backbone literals.
To increase the proportion of backbone literals found by Whitening Algorithm, we use two heuristic strategies to refine Whitening Algorithm, namely Whitening-based Algorithm.
First, we check whether the generated assignment is a model to eliminate some of the non-backbone literals returned by Whitening Algorithm.
Moreover, we use assumptions features of MINISAT \cite{JLM15} to find some of accurate backbone literals.
With the refinement of these three heuristic strategies, Whitening-based Algorithm is able to return a set of literals that are highly likely to be backbone.


\medskip
\noindent{\bf Computing exact backbone.}
At this step, we use Algorithm 3 (Iterative algorithm) from \cite{JLM15} to compute backbone.
This algorithm uses SAT solvers to test whether a literal is a backbone literal or not.
For instance, if $\Phi\wedge \neg l$ is unsatisfiable but $\Phi$ is satisfiable, then $l$ must be a backbone literal of $\Phi$.

We first iteratively select one literal $l$ from $\BLap(\Phi)\setminus \NBLap(\Phi)$ such that $\lambda \models \neg l$ and test $l$ by checking the satisfiability of $\Phi\wedge l$ (dashed area in Figure \ref{flow}).
If $l$ is a backbone, we will add $l$ into $\Phi$ as a clause. Adding known backbone literals into $\Phi$ as clauses potentially speedups the later SAT testing \cite{JLM15,MPA2015}.
Then, we do the same testing for literals from $\Lit(\Phi)\setminus (\NBLap(\Phi)\cup\BLap(\Phi))$ (dotted area in Figure \ref{flow}).
After this step, the exact backbone and non-backbone are found.


In general, one can directly test all the literals to compute backbone without the two approximations.
However, the test heavily relies on SAT solving which may be time-cost.
Our approach makes two contributions compared to this na\"{\i}ve approach.
One is that we reduce the number of SAT calls using the known non-backbone literals $\BLap(\Phi)$.
The another one is that we first check literals that have high probability to be backbone literals so that backbone literals can be found as early as possible.

