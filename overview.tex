\section{Overview of our Approach}\label{sec:overview}
In this section, we present the overview of our approach, called BONE, for computing backbone. Figure 1 depicts the framework of BONE.
% We show the overview of our approach \tool in Figure \ref{flow}.
Taking a satisfiable formula $\Phi$ as an input, \tool first computes a subset of non-backbone $\NBLap(\Phi)\subseteq \NBL(\Phi)$.
Then, \tool computes
% an intermediate set of backbone $\BLap(\Phi)$
approximation $\BLap(\Phi)$ of the backbone
based on the set $\NBLap(\Phi)$, where each literal $l\in \BLap(\Phi)$ has a high possibility to be a backbone literal of $\Phi$.
Finally, \tool removes non-backbone literals from $\BLap(\Phi)$ and adds backbone literals into $\BLap(\Phi)$ to compute the exact backbone of $\Phi$.
\begin{figure*}[t]
   \includegraphics[scale=0.75]{Framework}
  \hspace*{30mm} \includegraphics[scale=0.75]{Fig-backbone}
   \caption{Overview of our approach}
   \label{flow}
\end{figure*}

% As shown in Figure \ref{flow}, $\NBLap(\Phi)$ only contains a part of non-backbone literals.
% Most of the literals in $\BLap(\Phi)$ are backbone, only a small part of them is non-backbone.
% With more known backbone literals, SAT testings are accelerated.

\medskip
\noindent{\bf Computing an under-approximation of non-backbone.}
Given a satisfiable formula $\Phi$, we first compute a model $\lambda$ of $\Phi$ by calling a SAT solver.
From the model $\lambda$, we compute a base under-approximation of non-backbone.
Later, we apply a Greedy-based algorithm to add more non-backbone literals into the base set, which results in $\NBLap(\Phi)$.

%The algorithm iteratively computes new models based on the original model $\lambda$, by changing exactly one literal at each iteration. K models will be generated after the k iterations. New non-backbone literals are found from each new model. The main idea of Greedy-based algorithm is changing the literal that satisfies the least clauses at each iteration.
% Choosing the literal that satisfies the least clauses will affects the least clauses, which lead to a higher possibility of finding a new model.
The algorithm iteratively computes new models until no new model can be found. We choose to change the literal that satisfies the least clauses at each iteration, as the number of clauses effected by this literal is the least one, provided a higher possibility to find a new model. K models will be generated after the k iterations. New non-backbone literals are found from each new model.

\medskip
\noindent{\bf Computing an approximation of backbone.}
At this step, we apply a Whitening-based algorithm to compute an approximation $\BLap(\Phi)$.
Whitening Algorithm was used to compute \emph{essential nodes} that cannot be colored as white without changing the color of its adjacent nodes in a graph coloring problem.


We consider essential nodes as 'possible' backbone literals in backbone computing.
To increase the proportion of backbone literals found by Whitening Algorithm, we use two heuristic strategies to refine Whitening Algorithm.
First, we check whether the generated assignment is a model to eliminate some of the non-backbone literals returned by Whitening-based Algorithm.
Moreover, we use assumptions features of MINISAT \cite{JLM15} to find some accurate backbone literals.
With the refinement of heuristic strategies, Whitening-based Algorithm is able to return a set of literals that are highly likely to be backbone.


\medskip
\noindent{\bf Computing exact backbone.}
Based on $\BLap(\Phi)$, we use Algorithm 3 (Iterative Algorithm) from \cite{JLM15} to compute backbone.
This algorithm uses SAT solvers to test whether a literal is a backbone literal or not.
For instance, if $\Phi\wedge \neg l$ is unsatisfiable but $\Phi$ is satisfiable, then $l$ must be a backbone literal of $\Phi$.

We first iteratively select one literal $l$ from $\BLap(\Phi)\setminus \NBLap(\Phi)$ such that $\lambda \models \neg l$ and test $l$ by checking the satisfiability of $\Phi\wedge l$ (dashed area in Figure \ref{flow}).
If $l$ is a backbone, we will add $l$ into $\Phi$ as a clause. Adding known backbone literals into $\Phi$ as clauses potentially speedups the later SAT testing \cite{JLM15,MPA2015}.
Then, we do the same testing for literals from $\Lit(\Phi)\setminus (\NBLap(\Phi)\cup\BLap(\Phi))$ (dotted area in Figure \ref{flow}).
After this step, the exact backbone and non-backbone are found.


Comparing to the approach of directly test all literals in $\Lit(\Phi)$, there are two contributions of \tool.
One is that we reduce the number of SAT calls using the known non-backbone literals $\BLap(\Phi)$.
The another one is that we first check literals that have high probability to be backbone literals so that backbone literals can be found as early as possible.




